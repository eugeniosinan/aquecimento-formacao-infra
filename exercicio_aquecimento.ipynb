{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aquecimento para a forma√ß√£o em infraestrutura\n",
    "\n",
    "## Etapas\n",
    "\n",
    "Aqui ser√£o descritas as etapas do desafio que, idealmente, devem ser seguidas de forma sequencial. Para o caso de dificuldade em alguma etapa, voc√™ poder√° seguir para a pr√≥xima, se assim desejar.\n",
    "\n",
    "### Etapa 1: Entendendo os dados üé≤\n",
    "\n",
    "- **Objetivo:** nessa etapa, voc√™ deve somente ingerir dados da API do `randomuser.me` e observar o formato dos dados, tentando imaginar como eles poderiam ser usados para construir uma tabela.\n",
    "- **Descri√ß√£o da solu√ß√£o:** a solu√ß√£o dessa etapa consiste em uma fun√ß√£o para consumir a API na URL `https://randomuser.me/api/` e retornar um dicion√°rio com os dados.\n",
    "- **Links √∫teis:**\n",
    "  - Documenta√ß√£o da API: https://randomuser.me/documentation\n",
    "  - Introdu√ß√£o a ingest√£o de dados via API: https://www.dataquest.io/blog/python-api-tutorial/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\":[{\"gender\":\"female\",\"name\":{\"title\":\"Mrs\",\"first\":\"Mathilde\",\"last\":\"Blanc\"},\"location\":{\"street\":{\"number\":8188,\"name\":\"Place du 8 F√©vrier 1962\"},\"city\":\"Aix-En-Provence\",\"state\":\"Dordogne\",\"country\":\"France\",\"postcode\":84584,\"coordinates\":{\"latitude\":\"-15.9301\",\"longitude\":\"18.5877\"},\"timezone\":{\"offset\":\"-5:00\",\"description\":\"Eastern Time (US & Canada), Bogota, Lima\"}},\"email\":\"mathilde.blanc@example.com\",\"login\":{\"uuid\":\"b174d403-d1cf-44e4-8696-5a544941ca87\",\"username\":\"happygoose667\",\"password\":\"montag\",\"salt\":\"fW0p4rsB\",\"md5\":\"f6f9cb39c3d7d2b45e381766abda5e93\",\"sha1\":\"ec77d538167f1d2bde7eda0331efb5045fc27880\",\"sha256\":\"388336a979ae9408e8a05c27d739569945de4856681aeae1e1a9d3c68a8b31fb\"},\"dob\":{\"date\":\"1963-05-07T04:42:55.184Z\",\"age\":59},\"registered\":{\"date\":\"2008-05-16T20:32:30.885Z\",\"age\":14},\"phone\":\"03-20-76-54-05\",\"cell\":\"06-80-10-32-02\",\"id\":{\"name\":\"INSEE\",\"value\":\"2630484232665 79\"},\"picture\":{\"large\":\"https://randomuser.me/api/portraits/women/30.jpg\",\"medium\":\"https://randomuser.me/api/portraits/med/women/30.jpg\",\"thumbnail\":\"https://randomuser.me/api/portraits/thumb/women/30.jpg\"},\"nat\":\"FR\"}],\"info\":{\"seed\":\"7613f80e8d87f82c\",\"results\":1,\"page\":1,\"version\":\"1.4\"}}\n"
     ]
    }
   ],
   "source": [
    "## Importando a biblioteca\n",
    "import requests\n",
    "\n",
    "## Fazendo a requisi√ß√£o √† API e recebendo o objeto de retorno na variavel \"r\"....esse √© um objeto da biblioteca request\n",
    "r = requests.get( 'https://randomuser.me/api/' )\n",
    "\n",
    "## tranformando o objeto request em string e imprimindo na tela.\n",
    "print( r.text )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 2: Coletando dados üíæ\n",
    "\n",
    "- **Objetivo:** nessa etapa, voc√™ deve coletar dados da API e armazen√°-los em um arquivo CSV.\n",
    "- **Descri√ß√£o da solu√ß√£o:** a solu√ß√£o dessa etapa consiste em uma fun√ß√£o para coletar uma quantidade `n` de dados da API (sendo `n` um valor fornecido via par√¢metro da fun√ß√£o), manipul√°-los para montar um `pandas.DataFrame` e salvar o resultado em um arquivo CSV.\n",
    "- **Links √∫teis:**\n",
    "  - Documenta√ß√£o da API: https://randomuser.me/documentation\n",
    "  - Documenta√ß√£o do Pandas: https://pandas.pydata.org/docs/\n",
    "- **Dicas:**\n",
    "  - Para tornar os dados mais f√°ceis de manipular no futuro, fa√ßa com que o `DataFrame` seja \"plano\", ou seja, cada coluna seja um √∫nico atributo do objeto.\n",
    "  - Para ter dados suficientes para uma an√°lise razo√°vel nas pr√≥ximas etapas, recomendamos `n>=500`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importando as bibliotecas\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "\n",
    "## Fazendo a requisi√ß√£o √† API e setando um n de 600 registros\n",
    "## r ser√° um objeto da biblioteca request\n",
    "r = requests.get( 'https://randomuser.me/api/?results=1500' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tranformar o objeto r em uma string json \n",
    "dict= json.loads(r.text)\n",
    "\n",
    "## Normalizar a string json, pois existem objetos aninhados. Estes receberam o separador \"_\" \n",
    "df = json_normalize( dict['results'], sep = \"_\" )\n",
    "df.to_csv( \"registros_api.csv\" , sep=';',encoding='utf8', index=False)\n",
    "## print(df)Ser√° "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 3: Manipulando dados üìù\n",
    "\n",
    "- **Objetivo**: agora, voc√™ pode observar que, na base de dados obtida, devido √†s diferentes nacionalidades dos usu√°rios, os n√∫meros de telefone e celular t√™m formatos diferentes. Voc√™ deve transform√°-los para um formato √∫nico, escolhido arbitrariamente.\n",
    "- **Descri√ß√£o da solu√ß√£o**: uma fun√ß√£o que recebe, como par√¢metro, um `pandas.DataFrame` e retorna um `pandas.DataFrame` com as mesmas colunas, mas com os n√∫meros de telefone e celular formatados de forma √∫nica.\n",
    "- **Links √∫teis:**\n",
    "- Documenta√ß√£o do Pandas: https://pandas.pydata.org/docs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_phone_field(df, colname):\n",
    "\n",
    "    if colname in df.columns:\n",
    "        \n",
    "        def formatPhone(x):\n",
    "            x = ''.join(c for c in x if c.isdigit())   # Removendo os caracters n√£o num√©ricos\n",
    "            x = x.zfill(8)   # Completando com zeros a esquerda caso tenha menos de 7 numeros\n",
    "            x = x[-8:]   # pegando os 7 n√∫meros da direita para a esquerda\n",
    "            x = x[:4] + '-' + x[4:]\n",
    "            return x   # retorno da fun√ß√£o\n",
    "\n",
    "        df[colname] = df[colname].apply(formatPhone) # Aplicando a fun√ß√£o na coluna do dataframe\n",
    "        \n",
    "    else:\n",
    "        print(\"Variavel nao existe!\")\n",
    "    \n",
    "## Aplicando a fun√ß√£o de formata√ß√£o dos n√∫meros de telefone e celular nas respectivas colunas do dataframe\n",
    "format_phone_field(df, \"phone\")\n",
    "format_phone_field(df, \"cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 4: Analisando dados sem agrupamento üìä\n",
    "\n",
    "- **Objetivo**: com seus dados devidamente tratados, voc√™ deve gerar os seguintes itens:\n",
    "  - Um relat√≥rio em texto (n√£o precisa de formata√ß√£o) contendo:\n",
    "    - A porcentagem dos usu√°rios por g√™nero\n",
    "    - A porcentagem dos usu√°rios por pa√≠s\n",
    "  - Uma imagem contendo um gr√°fico de distribui√ß√£o da idade dos usu√°rios (a biblioteca utilizada para o `plot` pode ser qualquer uma).\n",
    "- **Descri√ß√£o da solu√ß√£o**: uma fun√ß√£o que recebe, como par√¢metro, um `pandas.DataFrame` e gera dois arquivos: um relat√≥rio em texto e outro contendo um gr√°fico de distribui√ß√£o da idade dos usu√°rios.\n",
    "- **Links √∫teis:**\n",
    "  - Documenta√ß√£o do Pandas: https://pandas.pydata.org/docs/\n",
    "  - Documenta√ß√£o do Matplotlib: https://matplotlib.org/\n",
    "  - Documenta√ß√£o do Seaborn: https://seaborn.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "df_gender = df.gender.value_counts().rename_axis('gender').to_frame('total').reset_index()\n",
    "df_gender[\"percentage\"] = round ( df_gender.total / df_gender.total.sum() * 100, 0 )\n",
    "df_gender\n",
    "\n",
    "df_country = df.location_country.value_counts().rename_axis('country').to_frame('total').reset_index()\n",
    "df_country[\"percentage\"] = round ( df_country.total / df_country.total.sum() * 100, 0 )\n",
    "df_country\n",
    "\n",
    "html = df_country.to_html()\n",
    "\n",
    "\n",
    "with open(\"aquecimento.html\", 'w') as arquivo:\n",
    "    arquivo.write( \n",
    "        \"<h1> Relat√≥rio Etapa 04</h1> \\n\" +\n",
    "        \"<h3> Percentual por sexo</h3>\" +\n",
    "        df_gender.to_html() + \"\\n\\n\\n\" +\n",
    "        \"<h3> Percentual por p√°is</h3>\" +\n",
    "        df_country.to_html()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       50 a 59\n",
       "1       50 a 59\n",
       "2       20 a 29\n",
       "3       30 a 39\n",
       "4       60 a 69\n",
       "         ...   \n",
       "1495    60 a 69\n",
       "1496    30 a 39\n",
       "1497    20 a 29\n",
       "1498    30 a 39\n",
       "1499    50 a 59\n",
       "Name: fx_etaria, Length: 1500, dtype: category\n",
       "Categories (6, object): ['20 a 29' < '30 a 39' < '40 a 49' < '50 a 59' < '60 a 69' < '70 a 79']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Escolhendo os binds\n",
    "print( df['dob_age'].min() ) ## 21\n",
    "print(  df['dob_age'].max()) ## 77\n",
    "\n",
    "\n",
    "bins= [ 20, 30, 40, 50, 60, 70, 80]\n",
    "labels = ['20 a 29', '30 a 39', '40 a 49', '50 a 59','60 a 69', '70 a 79']\n",
    "\n",
    "df['fx_etaria'] = pd.cut( df['dob_age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "df_fx_etaria = df.groupby(by=['fx_etaria'], dropna=False).count()[['gender']].rename(columns={'gender':'total'}).reset_index()\n",
    "\n",
    "df.fx_etaria\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(df, x=\"fx_etaria\")\n",
    "fig.show()\n",
    "\n",
    "print( df.dob_age.describe() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 5: Analisando dados com agrupamento üìä\n",
    "\n",
    "- **Objetivo**: utilizar t√©cnicas de agrupamento para descobrir usu√°rios que moram no mesmo pa√≠s e estado.\n",
    "- **Descri√ß√£o da solu√ß√£o**: uma fun√ß√£o que recebe, como par√¢metro, um `pandas.DataFrame` e retorna um `pandas.DataFrame` com as mesmas colunas, mas com os dados agrupados por pa√≠s e estado.\n",
    "- **Links √∫teis:**\n",
    "  - Documenta√ß√£o do Pandas: https://pandas.pydata.org/docs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               total\n",
      "location_country location_state                     \n",
      "Australia        Australian Capital Territory      7\n",
      "                 New South Wales                  16\n",
      "                 Northern Territory                8\n",
      "                 Queensland                       13\n",
      "                 South Australia                   6\n",
      "...                                              ...\n",
      "United States    Vermont                           2\n",
      "                 Washington                        2\n",
      "                 West Virginia                     2\n",
      "                 Wisconsin                         1\n",
      "                 Wyoming                           1\n",
      "\n",
      "[514 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "## Fun√ß√£o que recebe um DF e dois nomes de coluna como parametros e retorna um DF com o agrupamento de duas colunas caso essas existam no df passado como parametro\n",
    "def group_country_state(df, col1, col2):\n",
    "       \n",
    "    lista_campos = [ col1, col2 ]\n",
    "    lista_colunas = df.columns\n",
    "\n",
    "    ## verificar se todos os campos da lista_campos est√£o contidos na lista_colunas\n",
    "    check = all( item in lista_colunas for item in  lista_campos) ## Return true or false\n",
    "\n",
    "    if check is True:\n",
    "        df_group = df.groupby(by= [ col1, col2 ], dropna=False).count()[['gender']].rename( columns={'gender':'total'} )\n",
    "        return df_group\n",
    "\n",
    "table_group = group_country_state(df, 'location_country', 'location_state')\n",
    "print(table_group )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 6 (opcional): Particionando dados üéº\n",
    "\n",
    "- **Objetivo**: realizar o particionamento dos dados em formato Hive utilizando as informa√ß√µes de pa√≠s e estado de cada usu√°rio.\n",
    "- **Descri√ß√£o da solu√ß√£o**: uma fun√ß√£o que recebe, como par√¢metro, um `pandas.DataFrame` e salva todos os dados em arquivos CSV particionados por pa√≠s e estado.\n",
    "- **Links √∫teis:**\n",
    "  - Documenta√ß√£o do Pandas: https://pandas.pydata.org/docs/\n",
    "  - Documenta√ß√£o do Hive: https://hive.apache.org/\n",
    "  - Documenta√ß√£o do BigQuery para dados particionados em Hive: https://cloud.google.com/bigquery/docs/hive-partitioned-queries-gcs\n",
    "- **Exemplo para esclarecimento**: supondo que haja um `DataFrame` conforme o seguinte:\n",
    "\n",
    "  ```python\n",
    "      ano  mes sigla_uf dado\n",
    "  0  2020    1       SP    a\n",
    "  1  2021    2       SP    b\n",
    "  2  2020    3       RJ    c\n",
    "  3  2021    4       RJ    d\n",
    "  4  2020    5       PR    e\n",
    "  5  2021    6       PR    f\n",
    "  6  2021    6       PR    g\n",
    "  7  2025    9       PR    h\n",
    "  ```\n",
    "\n",
    "  Caso quis√©ssemos particionar o `DataFrame` utilizando as colunas `ano`, `mes` e `sigla_uf`, o resultado obtido seria a seguinte estrutura de diret√≥rios:\n",
    "\n",
    "  ![Exemplo de particionamento](./img/exemplo-particao.png)\n",
    "\n",
    "  Cada arquivo gerado, ent√£o, teria o seguinte formato (esse em quest√£o seria o `ano=2025/mes=9/sigla_uf=PR/data.csv`):\n",
    "\n",
    "  ```python\n",
    "    dado\n",
    "  0    h\n",
    "  ```\n",
    "\n",
    "  Note que, no arquivo CSV gerado, as colunas referentes √†s informa√ß√µes utilizadas para particionamento s√£o removidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fun√ß√£o para criar as pastas por pa√≠s e cidade\n",
    "def create_partitions_country_state( df ):\n",
    "    \n",
    "    import os\n",
    "\n",
    "    ## Pegando o caminho da pasta do script\n",
    "    path_script = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "\n",
    "    # Criar se nao existir o diretorio\n",
    "    if not os.path.exists(os.path.join( path_script,'partitions')):\n",
    "        os.makedirs(os.path.join( path_script,'partitions')) \n",
    "\n",
    "    path_partitions = os.path.join( path_script,'partitions')\n",
    "\n",
    "    ## Criado um df com agrupamento de cidade e pais com o index resetado para n√£o conter index multiplo\n",
    "    df2 = df.groupby(by= [ 'location_country','location_state' ], dropna=False).count()[['gender']].rename( columns={'gender':'total'} ).reset_index()\n",
    "\n",
    "    ## Criar dicion√°rio com cidade na chave e pa√≠s no valor\n",
    "    dicionario_cidade_capital = pd.Series(df2.location_country.values,index=df2.location_state).to_dict()\n",
    "\n",
    "    ## iterar neste dicionario para criar os bancos a partir das chaves e valores do dicionario contendo o par√¢metro de sele√ßao da consulta ao df principal\n",
    "    for key, value in dicionario_cidade_capital.items():\n",
    "        \n",
    "        pais = value\n",
    "        cidade = key\n",
    "        filename = f\"{pais}_{cidade}.csv\" \n",
    "\n",
    "        path_pais = os.path.join( path_partitions,\"country=\" + pais )\n",
    "        path_cidade = os.path.join( path_partitions, \"country=\" + pais, \"state=\" + cidade )\n",
    "\n",
    "        \n",
    "        if not os.path.exists( path_pais ):     ## Criar se nao existir o diretorio de pa√≠s\n",
    "            os.makedirs( path_pais )\n",
    "        ## \n",
    "        if not os.path.exists( path_cidade ):   ## riar se nao existir o diretorio de cidades\n",
    "            os.makedirs( path_cidade )\n",
    "\n",
    "        ## Criar os CSV's dentro das pastas\n",
    "        df.loc[ ( df.location_country == pais ) & ( df.location_state == cidade )].to_csv( path_cidade + \"//\" +filename )\n",
    "\n",
    "try:\n",
    "    ## Aplicando a fun√ß√£o e criando as parti√ß√µes\n",
    "    create_partitions_country_state( df )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 7: Parametrizando seu c√≥digo ‚öôÔ∏è\n",
    "\n",
    "- **Objetivo:** nessa etapa, voc√™ deve parametrizar seu c√≥digo para que ele seja executado com valores diversos fornecidos pelo usu√°rio.\n",
    "- **Descri√ß√£o da solu√ß√£o:** a solu√ß√£o dessa etapa consiste em uma fun√ß√£o principal que recebe diversos par√¢metros e executa as diversas etapas descritas anteriormente em fun√ß√£o dos par√¢metros fornecidos. Note que essa etapa √© crucial para que seu c√≥digo se torne reutiliz√°vel.\n",
    "- **Dicas:**\n",
    "  - Tente pensar no maior n√∫mero de par√¢metros que sejam relevantes para sua pipeline de dados, sem afetar sua funcionalidade.\n",
    "  - Colocar valores padr√£o para alguns desses par√¢metros reduz o √¥nus do usu√°rio de preench√™-los por conta pr√≥pria.\n",
    "\n",
    "\n",
    "# CIE - Centro de Intelig√™ncia Epidemiol√≥gica\n",
    "![](https://svs.rio.br/epirio/img/CIE_RODAPE.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
